# Feature Likelihood Score: Evaluating Generalization of Generative Models Using Samples
Repository for computing **FLS**. Currently, mainly supports evaluating image generation but the code can be extended to other data modalities.

## Setup
```bash
git clone https://github.com/marcojira/fls.git
cd fls
pip install -r requirements.txt
```

## Quick start
We provide two ways to compute FLS:

```bash
# Usage from the command line
python fls.py --train=/path/to/train --test=/path/to/test --gen=/path/to/generated
```

```python
# Usage from python
import fls

def gen_samples():
    z = torch.randn(32, 100)
    return G(z).detach().cpu().numpy()

fls.compute_score(train="path/to/train.pt", test="path/to/test.pt", gen=gen_samples)
```

Specifically, computing FLS requires 3 sets of samples:
- **Training samples**: Samples used to train the generative model
- **Test samples**: Samples that from the same distribution as the training samples but were not used to train the generative model
- **Generated samples**: Samples generated by the generative model

Each of these sets can come from 3 sources:
### Folder of images
Path to a folder containing image samples (either as `.jpg` or `.png`)
```bash
# Usage from the command line
fls.py --train=/path/to/train --test=/path/to/test --gen=/path/to/generated
```

```python
# Usage from python (string of directory paths are assumed to be folders of images)
fls.compute_score("path/to/train", "path/to/test", "path/to/generated")
```

### Pre-computed features in a `.pt` file
Path to a `.pt` file which contains a NxD tensor (where N is the number of samples and D is the dimensionality of the feature space)
```bash
# Usage from the command line
fls.py --train=/path/to/train.pt --test=/path/to/test.pt --gen=/path/to/generated.pt
```

```python
# Usage from python (string paths ending in `.pt` are assumed to be pre-computed features)
fls.compute_score("path/to/train.pt", "path/to/test.pt", "path/to/generated.pt")
```

### Python function (without arguments) that returns samples
For use from Python (to skip over the time-consuming process of saving samples to disk and then loading them).
```python
# Usage from python (functions are assumed to return samples)

# Example wrapping a dataloader

# Example of a function that returns samples from some generated model
def gen_samples():
    z = torch.randn(32, 100)
    return G(z).detach().cpu().numpy()

fls.compute_score(train="path/to/train.pt", test="path/to/test.pt", gen=gen_samples)
```

## Metrics
By default, only FLS is computed. However, it is possible to also compute the following metrics:
- `"FID"`: Computes the FID score between the training and test samples
- `"AuthPct"`: Percentage of authentic samples (as per https://arxiv.org/abs/2102.08921)
- `"CTScore"`: As defined in https://github.com/casey-meehan/data-copying
- `"FLSOverfit"`: Computes the percentage of overfit Gaussians.

To compute other metrics as well, pass a list of metric names to the `metrics` argument:
```python
fls.compute_score("path/to/train.pt", "path/to/test.pt", gen_samples, metrics=["FID", "FLS", "AuthPct", "CTScore", "FLSOverfit"])
```

## Feature caching
By default, computed features are not cached. However, for sets of features that will be used often, it is possible to cache them in a `.pt` file. For example when you want to monitor FLS during training, the train set and test set are the same and do not to be mapped to the feature space at every epoch and their features can be cached to save time. To do so, pass a path to the `{train,test,gen}_save` argument.

```python
# Calling this for the first time will cache train/test features in their given paths
fls.compute_score("path/to/train", "path/to/test", gen_samples, train_save="path/to/train.pt", test_save="path/to/test.pt")

# If the features have already been cached, they will be loaded from the given paths
fls.compute_score("path/to/train", "path/to/test", gen_samples, train_save="path/to/train.pt", test_save="path/to/test.pt" )
```

## Feature space
We provide feature extractors for InceptionV3 (as used in https://github.com/mseitzer/pytorch-fid) and CLIP (https://github.com/openai/CLIP). By default, Inception V3 is used. To change the feature extractor:
```python
from features.CLIPFeatureExtractor import CLIPFeatureExtractor

clip = CLIPFeatureExtractor()
fls.compute_score("path/to/train", "path/to/test", gen_samples, feature_extractor=clip)
```

### Adding a new feature space
To create your own FeatureExtractor, create a class that inherits from `features/FeatureExtractor.py`.

## File structure
- `datasets/`: Extensions of PyTorch dataset utilities.
- `features/`: Modules to map samples to different feature spaces
- `metrics/`: Modules for computing various metric values (FLS, FID, AuthPct, CTScore)